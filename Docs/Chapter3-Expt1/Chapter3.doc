Chapter 3 – Clustering Based

What is the methods
	Here we describe the algorithm, first patching the data, 
	the random selection of patches, finding clusters of the patches
	Mapping clusters to GT
	For new sample → Nearest Cluster, replace by GT cluster
	Repatch to get the image

Define the algorithm
How the data is generated
Show the clusters formed
	Clusters
Preprocessing Steps
Results

1) No of clusters
2) Sample Size
3) ??
The chapter aims to present our clustering based image segmentation methods.
The chapter is divided into 4 parts. In the first part we discuss the basic framework of our algorithm. Part 2 and Part3 talk about the various preprocessing methods and how the methods was applied to our problem.


2.1 Image segmentation Framework

Our image segmentation framework takes its input a list of fundus images I = (I_1, I_2.... I_n) and their correspoding ground truth segmentation maps S = (S_1, S_2.....S_n). The given fundus images can be grayscale images or RGB color images. Each of the given segmentaion maps in S, is the same size as that of correspoding fundus image in I. The ground truth segmentation is a binary image I.e, each pixel in the segmentation map is either 1 or a 0, where 1 depeicts the presenece of a vessel and 0 for the background.

So given a training dataset consisting of fundus images I and segmentation maps S, the aim is to define a framework, which can learn to predict the segmentation map S' for an unknown new image I'.

The proposed problem is dealt in a patch based framework. Each image pixel in the image is represented by a patch centered around the pixel. The image is decomposed into such dense patches.

Given an Image pixel I(x,y) we compute a patch of size k x k around the pixel I(x,y). Each image is then described by such patches.

Patches are computed both for the Fundus images and their corresoponding binary segmentation map images. For an Image I, and its segmentation map S, the patches our denoted by 
I ~ [Ip_1,Ip_2 …]  and S ~ [Sp_1,Sp_2,....]

The aim of our thesis is to develop algorithms which predict the Segmentation patch for a given image patch.

During the training process, the algorithms aim to learn a set of image representation patches describing the patches from the training set.

Give a training set consisting of image patches X={X1, X2, X3. … } and their corresponding ground truth patches Y = {Y1,Y2,Y3,...}, we aim to learn as set Xr = {Xr1,Xr2,.... } which can represent each and every patch of in the training images X.

In the prediction phase, a single channel of the image is taken and dense patches (patches per pixel are calculated ) and fed to the classifier. The classifer predicts the GT patches for each image patch. The ground truth patches are the recombined to obtain the segmentation map for the image.

Preprocessing
In our task we have explored some of the preprocessing steps including Patch Normalization, Contrast streteching, Local contrast nomralization.

All the input patches are normalizaed by subtracting the mean and standard deviation per patch. In addition to this we also test with normalizing the entire image before patch generation.

In some of the experiments, we improve the image contrast by utilizing Contrast Limited Adaptive Histogram Equalization (CLAHE) as explained in section{}.

Rotations
To provide for rotational invariance and learn better representatives, rotated patches are also included in our learning phase. Each of the training images are additionaly rotated at angles of 30,60,90 and patches are calculated.


Datasets
For testing the performance of our algorithm and check for robustness, we train and test our system on the following publically available datasets.

1) DRIVE Dataset
2) STARE Dataset
3) Aria Online
4) HRF dataset

In the next 2 chapters, we discuss our two models used to learn the image representatives.

